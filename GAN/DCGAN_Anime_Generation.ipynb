{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_Anime_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdCPw29FKKEH",
        "colab_type": "code",
        "outputId": "0d719999-4a57-4d9e-8351-e98958e512aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import glob\n",
        "import io\n",
        "import math\n",
        "import time\n",
        "\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import Sequential,Input,Model\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Conv2D,Dense,Flatten,BatchNormalization,LeakyReLU,ReLU,Reshape,UpSampling2D,Activation,MaxPooling2D\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#from scipy.misc import imread,imsave\n",
        "from imageio import imread , imsave\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmV3jzQ1Ore0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#K.set_image_data_format()\n",
        "np.random.seed(1337)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqYeyUdTPdFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "  gen_model = Sequential()\n",
        "\n",
        "  gen_model.add(Dense(input_dim = 100, output_dim = 2048))\n",
        "  gen_model.add(ReLU())\n",
        "  \n",
        "  gen_model.add(Dense(256 * 8 * 8))\n",
        "  gen_model.add(BatchNormalization())\n",
        "  gen_model.add(ReLU())\n",
        "  gen_model.add(Reshape((8, 8, 256), input_shape = (256 * 8 * 8,)))\n",
        "  gen_model.add(UpSampling2D(size=(2,2)))\n",
        "\n",
        "  gen_model.add(Conv2D(128,(5,5),padding = 'same'))\n",
        "  gen_model.add(ReLU())\n",
        "  gen_model.add(UpSampling2D(size = (2,2)))\n",
        "\n",
        "  gen_model.add(Conv2D(64,(5,5),padding = 'same'))\n",
        "  gen_model.add(ReLU())\n",
        "  gen_model.add(UpSampling2D(size=(2,2)))\n",
        "\n",
        "  gen_model.add(Conv2D(3,(5,5),padding = 'same'))\n",
        "  gen_model.add(Activation('tanh'))\n",
        "\n",
        "  return gen_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1o5OBZfUxNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "\n",
        "  dis_model = Sequential()\n",
        "\n",
        "  dis_model.add(Conv2D(128,(5,5),padding = 'same',input_shape = (64,64,3)))\n",
        "  dis_model.add(LeakyReLU(alpha=0.2))\n",
        "  dis_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  dis_model.add(Conv2D(256,(3,3)))\n",
        "  dis_model.add(LeakyReLU(alpha=0.2))\n",
        "  dis_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  dis_model.add(Conv2D(512,(3,3)))\n",
        "  dis_model.add(LeakyReLU(alpha=0.2))\n",
        "  dis_model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  dis_model.add(Flatten())\n",
        "  dis_model.add(Dense(1024))\n",
        "  dis_model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  dis_model.add(Dense(1))\n",
        "  dis_model.add(Activation('sigmoid'))\n",
        "\n",
        "  return dis_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c59LmlzrUy-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_adversarial_model(gen_model,dis_model):\n",
        "  model = Sequential()\n",
        "  model.add(gen_model)\n",
        "  dis_model.trainable = False\n",
        "  model.add(dis_model)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAjKxH77VE1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_log(callback,name,loss,batch_no):\n",
        "\n",
        "  summary = tf.summary()\n",
        "  summary_value = summary.value.add()\n",
        "  summary_value.simple_value = loss\n",
        "  summary_value.tag = name\n",
        "  callback.writer.add_summary(summary,batch_no)\n",
        "  callback.writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwj2VPXKXz2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_rgb(img):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.imshow(img)\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(\"Image\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtdM5-zUZL0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_rgb_img(img,path):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.imshow(img)\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(\"RGB Image\")\n",
        "  plt.savefig(path)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK7FlY5biJUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data scraping from the web , install the data below packages and run the commands to download the data \n",
        "\n",
        "!pip install --upgrade gallery-dl\n",
        "!pip install animeface\n",
        "!gallery-dl https://danbooru.donmai.us/posts?tags=face"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx7rGC2wli4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import animeface\n",
        "\n",
        "total_num_faces = 0\n",
        "\n",
        "for index,filename in enumerate(glob.glob('your data path')):\n",
        "  print(filename)\n",
        "\n",
        "  try:\n",
        "    im = Image.open(filename)\n",
        "    faces = animeface.detect(im)\n",
        "  except Exception as e:\n",
        "    print(\"Exception:{}\".format(e))\n",
        "\n",
        "    continue\n",
        "    if len(faces) == 0:\n",
        "      print(\"no faces found\")\n",
        "      continue\n",
        "\n",
        "      fp = faces[0].face.pos\n",
        "      coordinates = (fp.x,fp.y,fp.x+fp.width,fp.y+fp.height)\n",
        "      cropped_image = im.crop(coordinates)\n",
        "      cropped_image = cropped_image.resize((64,64),Image.ANTIALIAS)\n",
        "\n",
        "  cropped_image.save(\"{}\".format(filename))\n",
        "\n",
        "  print(\"cropped image saved\")\n",
        "\n",
        "  total_num_faces += 1\n",
        "  print(\"total numer of faces detected till now :\",total_num_faces)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7KPYBv_aPaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "\n",
        "  start_time = time.time()\n",
        "  dataset_dir = \"your data path\"\n",
        "  batch_size = 128\n",
        "  z_shape = 100\n",
        "  epochs = 5\n",
        "  dis_learning_rate = 0.1\n",
        "  gen_learning_rate = 0.1\n",
        "  #dis_momentum = 0.5\n",
        "  #gen_momentum = 0.5\n",
        "  #dis_nesterov = True\n",
        "  #gen_nesterov = True\n",
        "\n",
        "  dis_optimizer = Adam(learning_rate=  dis_learning_rate)\n",
        "  gen_optimizer = Adam(learning_rate= gen_learning_rate)\n",
        "\n",
        "  dis_model = build_discriminator()\n",
        "  dis_model.compile(loss = 'binary_crossentropy', optimizer = dis_optimizer)\n",
        "\n",
        "  gen_model = build_generator()\n",
        "  gen_model.compile(loss = 'binary_crossentropy',optimizer = gen_optimizer)\n",
        "\n",
        "  adversarial_model = build_adversarial_model(gen_model,dis_model)\n",
        "  adversarial_model.compile(loss = 'binary_crossentropy',optimizer = gen_optimizer)\n",
        "\n",
        "  tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time.time()),write_images=True,write_grads=True,write_graph=True)\n",
        "  tensorboard.set_model(gen_model)\n",
        "  tensorboard.set_model(dis_model)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(\"-------------------------\")\n",
        "    print(\"epoch:{}\".format(epoch))\n",
        "\n",
        "    dis_losses = []\n",
        "    gen_losses = []\n",
        "\n",
        "    all_images = []\n",
        "\n",
        "    for index,filename in enumerate(glob.glob(\"your data path\")):\n",
        "      all_images.append(imread(filename, flatten = False, mode = 'RGB'))\n",
        "\n",
        "    X = np.array(all_images)\n",
        "    X = (X-127.5) / 127.5\n",
        "    X = X.astype(np.float32)\n",
        "\n",
        "    #X = load_images()\n",
        "    num_batches = int(X.shape[0]) / batch_size\n",
        "\n",
        "    print(\"Number of batches:{}\".format(num_batches))\n",
        "\n",
        "    for index in range(num_batches):\n",
        "\n",
        "      print(\"Batch:{}\".format(index))\n",
        "\n",
        "      z_noise = np.random.normal(0,1,size = (batch_size,z_shape))\n",
        "\n",
        "      gen_images = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "      visualize_rgb(gen_images[0])\n",
        "\n",
        "      dis_model.trainable = True\n",
        "      image_batch = X[index * batch_size : (index+1) * batch_size]\n",
        "\n",
        "      y_real = np.ones((batch_size, )) * 0.9\n",
        "      y_fake = np.zeros((batch_size, )) * 0.1\n",
        "\n",
        "      dis_loss_real = dis_model.train_on_batch(image_batch,y_real)\n",
        "      dis_loss_fake = dis_model.train_on_batch(generated_images,y_fake)\n",
        "\n",
        "      d_loss = (dis_loss_real + dis_loss_fake)/2\n",
        "      print(\"d_loss:\",d_loss)\n",
        "\n",
        "      dis_model.trainable = False\n",
        "\n",
        "      z_noise = np.random.normal(0,1,size = (batch_size, z_shape))\n",
        "\n",
        "      g_loss = adversarial_model.train_on_batch(z_noise,y_real)\n",
        "\n",
        "      print(\"g_loss:\",g_loss)\n",
        "\n",
        "      dis_losses.append(d_loss)\n",
        "      gen_losses.append(g_loss)\n",
        "\n",
        "      if epoch % 5 == 0:\n",
        "        z_noise = np.random.normal(0,1,size = (batch_size,z_shape))\n",
        "        gen_images1 = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "        for img in gen_images1[:2]:\n",
        "          save_rgb_img(img,\"results/one_{}.png\".format(epoch))\n",
        "\n",
        "      print(\"epoch:{},dis_loss:{}\".formt(epoch,np.mean(dis_losses)))\n",
        "      print(\"epoch:{},gen_loss:{}\".format(epoch,np.mean(gen_losses)))\n",
        "\n",
        "      write_log(tensorboard,'discriminator_loss',np.mean(dis_losses),epoch)\n",
        "      write_log(tensorboard,'generator_loss',np.mean(gen_losses),epoch)\n",
        "    \n",
        "    gen_model.save(\"generator_model.h5\")\n",
        "    dis_model.save(\"discriminator_model.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKQH7PPhiHJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  train()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}